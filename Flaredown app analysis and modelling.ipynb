{"cells":[{"metadata":{"id":"0rfF7yE_Nzsx","colab_type":"text"},"cell_type":"markdown","source":"#**QPID Machine Learning/Data Science Challenge**"},{"metadata":{"id":"LDq-MzMsENGk","colab_type":"toc"},"cell_type":"markdown","source":">[QPID Machine Learning/Data Science Challenge](#scrollTo=0rfF7yE_Nzsx)\n\n>>[Introduction](#scrollTo=rm6JUOo3PkQ3)\n\n>>>[Problem Statement](#scrollTo=tcXSWw-895ez)\n\n>>[Details](#scrollTo=GZh7-oC8ELQh)\n\n>>>[Downloading the Dataset](#scrollTo=NkkA0ZzePwI8)\n\n>>>[Dataset Description](#scrollTo=mEXwMJQ-VWoR)\n\n>>>[Hints](#scrollTo=Tg8y-zLlxZNQ)\n\n>>>[Import Libraries](#scrollTo=JBt8Ino7PGDz)\n\n>>>[Code Samples](#scrollTo=i38zIcCZXg33)\n\n>>[Tasks](#scrollTo=TJTdm_qNYqqb)\n\n>>>[Part 1: Modeling](#scrollTo=2hcyIkRSXg82)\n\n>>>[Part 2: Additional Questions](#scrollTo=8VSLpzIMXg_a)\n\n"},{"metadata":{"id":"rm6JUOo3PkQ3","colab_type":"text"},"cell_type":"markdown","source":"## Introduction"},{"metadata":{"id":"M5De0xQ0N82g","colab_type":"text"},"cell_type":"markdown","source":"We'd like to get a better sense of your approach to and intuition for machine learning, natural language processing, data science, as well as your other technical and analytical skills. To that end, we'd like you to complete this ML challenge. \n\nIn this challenge, we provide you with some code samples using `pandas` and `scikit-learn`. You may use other python libraries as well as reference online resources to complete this challenge.\n\nThis is an interactive Jupyter notebook that allows you to write, comment on, and execute python code directly on Google's servers. If you are new to Jupyter notebooks, you can read more about them here: [https://jupyter.org/](https://jupyter.org/). **Please edit this notebook directly** and take as much time as you feel is reasonable to complete this exercise. \n"},{"metadata":{"id":"tcXSWw-895ez","colab_type":"text"},"cell_type":"markdown","source":"### Problem Statement\nThe goal of this notebook is to develop a model that predicts whether self-reported severity of [fibromyalgia](https://en.wikipedia.org/wiki/Fibromyalgia) **IMPROVED**, **WORSENED**, or stayed the **SAME** over a variable period of time for patients who have this condition. Below are instructions about how to download the data, as well as some sample code that generates such predictions. \n\n**Your goal is to improve on this model and show us how you think through such a problem.**\n"},{"metadata":{"id":"TJTdm_qNYqqb","colab_type":"text"},"cell_type":"markdown","source":"## Tasks\n\nThis challenge consists of two parts: modeling and addressing additional questions. The first part is to train a model and predict the change in status of fibromyalgia. The second part is to answer some questions in regards to your approach. \n"},{"metadata":{"id":"2hcyIkRSXg82","colab_type":"text"},"cell_type":"markdown","source":"### Part 1: Modeling\n\n\n\n1.   We will evaluate your results on a held-out test set. Therefore, please make sure that your code is clearly documented, so that we can easily run **your code** against our test set. The test set is formatted exactly the same as the dataset set we provided. **You will not be judged solely on the performance of the model.** We are also interested in your creativity and problem solving approach.  \n2.   Please report on how well the model did. You may choose to whatever metrics you find appropriate.\n"},{"metadata":{"id":"8VSLpzIMXg_a","colab_type":"text"},"cell_type":"markdown","source":"### Part 2: Additional Questions\n\nPlease answer the following questions at the bottom of the notebook when you have completed part 1:\n\n1.   If you've explored the data, please describe your observations about the dataset. \n2.   What approach (i.e. modeling & evaluation) did you use?\n3.   What features have you tried (please also include the ones that you do not include in your final model)?\n4.   Why did you use this approach?\n5.   How would you improve your model if you had more time?\n\n"},{"metadata":{"id":"GZh7-oC8ELQh","colab_type":"text"},"cell_type":"markdown","source":"## The Dataset"},{"metadata":{"id":"NkkA0ZzePwI8","colab_type":"text"},"cell_type":"markdown","source":"### Downloading the Dataset\n\nThe following is a function to download the datasets and then import it as a pandas `DataFrame` object. \n\nYou may need to sign in with your Google account when prompted."},{"metadata":{"id":"BhFSqnZ7y0Ri","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"# Install the PyDrive wrapper & import libraries.\n# This only needs to be done once per notebook.\n!pip install -U -q PyDrive","execution_count":0,"outputs":[]},{"metadata":{"id":"IBKYU8u_Uuf3","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"from pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\nfrom google.colab import auth\nfrom oauth2client.client import GoogleCredentials\n\nimport pandas as pd\nimport io\nimport json","execution_count":0,"outputs":[]},{"metadata":{"id":"-NDVz53BPyOz","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"# Authenticate and create the PyDrive client.\n# This only needs to be done once per notebook.\ndef download_dataset(file_id):\n  auth.authenticate_user()\n  gauth = GoogleAuth()\n  gauth.credentials = GoogleCredentials.get_application_default()\n  drive = GoogleDrive(gauth)\n\n  # Download a file based on its file ID.\n  downloaded = drive.CreateFile({'id': file_id})\n  content = downloaded.GetContentString()\n  \n  return pd.read_csv(io.StringIO(content))\n  ","execution_count":0,"outputs":[]},{"metadata":{"id":"mEXwMJQ-VWoR","colab_type":"text"},"cell_type":"markdown","source":"### Dataset Description\n\nThe dataset you will be using is a subset of the Chronic Illness dataset on Kaggle: https://www.kaggle.com/flaredown/flaredown-autoimmune-symptom-tracker\n\n\n\nFlaredown is an app that helps patients of chronic autoimmune and invisible illnesses improve their symptoms by avoiding triggers and evaluating their treatments. Each day, patients track their symptom severity, treatments and doses, and any potential environmental triggers (foods, stress, allergens, etc) they encounter.\n\n**About the data**\n\nInstead of coupling symptoms to a particular illness, Flaredown asks users to create their unique set of conditions, symptoms and treatments (“**trackables**”). They can then “check-in” each day and record the severity of symptoms and conditions, the doses of treatments, and “tag” the day with any unexpected environmental factors.\n\n**Condition**: an illness or diagnosis, for example Rheumatoid Arthritis, rated on a scale of **0 (not active) to 4 (extremely active)**.\n\n**Symptom**: self-explanatory, also rated on a 0–4 scale.\n\n**Treatment**: anything a patient uses to improve their symptoms, along with an optional dose, which is a string that describes how much they took during the day. For instance “3 x 5mg”.\n\n**Tag**: a string representing an environmental factor that does not occur every day, for example “ate dairy” or “rainy day”.\n\n**Food**: food items were seeded from the publicly-available USDA food database. Users have also added many food items manually.\n\n**Weather**: weather is pulled automatically for the user's postal code from the Dark Sky API. Weather parameters include a description, precipitation intensity, humidity, pressure, and min/max temperatures for the day.\n\nIf users do not see a symptom, treatment, tag, or food in our database (for instance “Abdominal Pain” as a symptom) they may add it by simply naming it. This means that the data requires some cleaning, but it is patient-centered and indicates their primary concerns.\n\n"},{"metadata":{"id":"u5CIc2gds8dB","colab_type":"text"},"cell_type":"markdown","source":"The following is a snippet of what the original dataset looks like:"},{"metadata":{"id":"7HeZ-6fMtDB-","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"sample_file_id = '1r4afwYJ3JC_8kJFMKbYea_7vnnXaFb1r'\nsample_df = download_dataset(sample_file_id)","execution_count":0,"outputs":[]},{"metadata":{"id":"G5AB07Hdtiyo","colab_type":"code","outputId":"c3f7ade5-e5e6-42c1-dfe1-2c772cdf8a4c","colab":{"base_uri":"https://localhost:8080/","height":607},"trusted":false},"cell_type":"code","source":"sample_df\n#sample_df['trackable_name'].value_counts()","execution_count":0,"outputs":[]},{"metadata":{"id":"xUaTD6_Hq58m","colab_type":"text"},"cell_type":"markdown","source":"The dataset we provided is a subset of the original dataset, and we grouped all the `trackable_type`, `trackable_name`, and `trackable_value` of a patient/user within a `checkin_date` into one JSON array. \n\nFor example: those 10 rows in the `DataFrame` above belong to the same user within the same `checkin_date`, so the trackable columns are aggregated into a JSON array as following:"},{"metadata":{"id":"zk6Vnc9rxBkz","colab_type":"code","outputId":"4a8e00e5-a00a-40d1-f673-af40dbcd7dae","colab":{"base_uri":"https://localhost:8080/","height":54},"trusted":false},"cell_type":"code","source":"sample_df.head(10)[['trackable_type', 'trackable_name', 'trackable_value']].to_json(orient='records')","execution_count":0,"outputs":[]},{"metadata":{"id":"fiHmyVUYxZIJ","colab_type":"text"},"cell_type":"markdown","source":"For this challenge, we want to compare the `trackable_value`, i.e. severity, of the condition of a user between two closest recorded dates in the dataset. (Please run the following code to download the training dataset.)"},{"metadata":{"id":"kX8KImkdu4Jn","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"train_file_id = '1hDM1VfaZ7o1moBN1IlcaFExfoE2Jeqgg'\ndataframe = download_dataset(train_file_id)\ndataframe['entries_from'] = dataframe.entries_from.apply(json.loads)\ndataframe['entries_to'] = dataframe.entries_to.apply(json.loads)","execution_count":0,"outputs":[]},{"metadata":{"id":"lIiGSVTuu6fW","colab_type":"code","outputId":"2fd082e7-3907-48ca-d0b9-f2ce4315317d","colab":{"base_uri":"https://localhost:8080/","height":289},"trusted":false},"cell_type":"code","source":"dataframe.head()\n#dataframe['entries_from']['trackable_type'].value_counts()","execution_count":0,"outputs":[]},{"metadata":{"id":"6jbQ_wJMnut6","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"","execution_count":0,"outputs":[]},{"metadata":{"id":"9duByuN0zWGb","colab_type":"text"},"cell_type":"markdown","source":"  Columns with the `from` suffix contain the records from the same earlier date, and the ones with the `to` suffix have the records from a later date. `entries_from` and `entries_to` columns are the aggregated JSON arrays mentioned above. \n  \n  Take the first row as example, the JSON array in the `entries_from` column contains all the `trackable` entries on the date (10/29/17) in `checkin_data_from` column, whereas that in the `entries_to` column contains all the `trackable` entries on the date (11/1/17) specified in the `checkin_data_to` column. \n  \n  The `status` column has three values: `IMPROVED`, `WORSENED`, and `SAME`. If the value in `value_from` is greater than that in `value_to`, that means the condition of a user has worsened between those two check-in dates; if `value_from` is less than `value_to` that means the condition has improved. If those two values are the same, that means the condition has remained the same. \n  \n  We ask you to build a model to predict the `status` of a patient's condition, whether it's `WORSERNED`, `IMPROVED`, or `SAME`."},{"metadata":{"id":"Tg8y-zLlxZNQ","colab_type":"text"},"cell_type":"markdown","source":"### Hints"},{"metadata":{"id":"pAfkFSfRxZP1","colab_type":"text"},"cell_type":"markdown","source":"We strongly encourage you to look at the values in the `entries_from` and `entries_to` columns and extract useful features from there. And please note that `trackable_value` can be free text. "},{"metadata":{"id":"nPW2iIMmGet-","colab_type":"text"},"cell_type":"markdown","source":"## Your Solution "},{"metadata":{"id":"_eNfs1tB4qGt","colab_type":"text"},"cell_type":"markdown","source":"The following is a working code sample. You are free to use the following code as part of your solution."},{"metadata":{"id":"JBt8Ino7PGDz","colab_type":"text"},"cell_type":"markdown","source":"### Import Libraries"},{"metadata":{"id":"wlFgZckhNh7r","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"from sklearn.base import TransformerMixin\nfrom sklearn.pipeline import FeatureUnion, Pipeline\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","execution_count":0,"outputs":[]},{"metadata":{"id":"i38zIcCZXg33","colab_type":"text"},"cell_type":"markdown","source":"### Generate Predictions\n\n"},{"metadata":{"id":"RueVpN5q7FU9","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"# download the dataset\ntrain_file_id = '1hDM1VfaZ7o1moBN1IlcaFExfoE2Jeqgg'\ndataframe = download_dataset(train_file_id)\ndataframe['entries_from'] = dataframe.entries_from.apply(json.loads)\ndataframe['entries_to'] = dataframe.entries_to.apply(json.loads)","execution_count":0,"outputs":[]},{"metadata":{"id":"TgKiQbap5kRk","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"from google.colab import files\nexample_df = dataframe.copy()\n#example_df.to_csv('example_df.csv')\n#files.download('example_df.csv')","execution_count":0,"outputs":[]},{"metadata":{"id":"4GViJ8ECQuL1","colab_type":"text"},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"id":"oVB0AnHC5ETi","colab_type":"code","outputId":"52891d2a-a45f-4653-cf92-37042584b6cf","colab":{"base_uri":"https://localhost:8080/","height":297},"trusted":false},"cell_type":"code","source":"dataframe.describe()","execution_count":0,"outputs":[]},{"metadata":{"id":"ATY02BDCkobT","colab_type":"text"},"cell_type":"markdown","source":"## **Distribution of gender**"},{"metadata":{"id":"zOlV0KdmVjHY","colab_type":"code","outputId":"7363841b-9595-4053-c0f0-969fb1a1cbba","colab":{"base_uri":"https://localhost:8080/","height":102},"trusted":false},"cell_type":"code","source":"import seaborn as sns\n\ndataframe['sex'].value_counts()","execution_count":0,"outputs":[]},{"metadata":{"id":"TDmPjpSXZtVb","colab_type":"text"},"cell_type":"markdown","source":"More than 83% of the data is given by female"},{"metadata":{"id":"kp-5p_4tjDPD","colab_type":"code","outputId":"c9bb1f91-d14c-4843-fca4-0c9f1aed16d6","colab":{"base_uri":"https://localhost:8080/","height":280},"trusted":false},"cell_type":"code","source":"fig = sns.countplot(x = 'sex', data= dataframe )","execution_count":0,"outputs":[]},{"metadata":{"id":"3_ty-WdY7sJi","colab_type":"code","outputId":"7803a061-c7f2-4938-983b-8cb9f03d1deb","colab":{"base_uri":"https://localhost:8080/","height":289},"trusted":false},"cell_type":"code","source":"dataframe.head()","execution_count":0,"outputs":[]},{"metadata":{"id":"yPsRQveBhORR","colab_type":"text"},"cell_type":"markdown","source":"# **Age Vs Status**\n\nIs there any pattern with Age and status of disease ?"},{"metadata":{"id":"fCLk_OFxhLUR","colab_type":"code","outputId":"8ff4b371-3a64-445a-a873-c84847b86ff5","colab":{"base_uri":"https://localhost:8080/","height":497},"trusted":false},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,8))\nsns.countplot(x = 'age',hue='status', data = dataframe, dodge= True)\n#plt.xticks(rotation = 45)\nplt.show()","execution_count":0,"outputs":[]},{"metadata":{"id":"urhqjG7LaTLm","colab_type":"text"},"cell_type":"markdown","source":"\n\n*   Most of the data consists of people with ages ranging from 22-35. Although      there is a sudden increase at age 43-45, There seems to be less elder users \n*   There is a notable peak in condition being SAME among all ages.\n\n*   Discrepencies in ages with values -1, 0 ,1. Replacing them with mean\n*   Most people with age 58 and 62 reported worsened disease status\n\n\n\n\n"},{"metadata":{"id":"cPC7DJGmomdf","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"import numpy as np\n\ndataframe['age'] = dataframe['age'].replace(0, int(np.mean(dataframe['age'])))\ndataframe[\"age\"] = dataframe['age'].replace(-1,int(np.mean(dataframe['age'])))\ndataframe[\"age\"] = dataframe['age'].replace(1,int(np.mean(dataframe['age'])))\n#dataframe['age'] = dataframe['age'].astype('Int64')","execution_count":0,"outputs":[]},{"metadata":{"id":"_0TdwkswfoLN","colab_type":"code","outputId":"ce946e82-86fa-47cb-d9a7-e2bd6dfe3a6f","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":false},"cell_type":"code","source":"int(dataframe[\"age\"].mean())","execution_count":0,"outputs":[]},{"metadata":{"id":"oJ8ttkesV-op","colab_type":"text"},"cell_type":"markdown","source":"#**Countries**\n\nGenerating latitude and longitude data to plot on a interactve map"},{"metadata":{"id":"eA575ByDdK_8","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"df = pd.DataFrame(dataframe['country'].unique())\ndf['values'] = df[0].apply(locator.geocode)\ndf['location'] = df['values'].apply(lambda loc: tuple(loc.point) if loc else None)\ndf[['latitude', 'longitude', 'altitude']] = pd.DataFrame(df['location'].tolist(), index=df.index)\ndf = df.drop(['location', 'values', 'altitude'], axis=1)\n#dataframe.drop(['latitude', 'longitude'], axis = 1, inplace= True)\ndataframe = dataframe.join(df.set_index(0), on='country')","execution_count":0,"outputs":[]},{"metadata":{"id":"pxpIgVovHBXH","colab_type":"code","outputId":"4e41cbe2-c36f-4d33-f358-3ab73a78489a","colab":{"base_uri":"https://localhost:8080/","height":85},"trusted":false},"cell_type":"code","source":"dataframe.columns","execution_count":0,"outputs":[]},{"metadata":{"id":"gV_YFteLAabQ","colab_type":"code","outputId":"8fdc2297-e273-4cad-a590-51e72b1dcc0c","colab":{"base_uri":"https://localhost:8080/","height":68},"trusted":false},"cell_type":"code","source":"dataframe['latitude'].isna().value_counts()","execution_count":0,"outputs":[]},{"metadata":{"id":"iQjsh7yLHgHc","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"dataframe[\"latitude\"] = dataframe.latitude.replace(np.nan,0)\ndataframe[\"longitude\"] = dataframe.longitude.replace(np.nan, 0)","execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","outputId":"6f50b697-791d-42fc-fcd7-15b174da304c","id":"oOEp4_0O67hg","colab":{"base_uri":"https://localhost:8080/","height":756},"trusted":false},"cell_type":"code","source":"import folium\nfrom folium.plugins import FastMarkerCluster\nfolium_map = folium.Map()\nFastMarkerCluster(data=list(zip(dataframe['latitude'].values, dataframe['longitude'].values))).add_to(folium_map )\nfolium.LayerControl().add_to(folium_map)\nfolium_map","execution_count":0,"outputs":[]},{"metadata":{"id":"Lb35BZI3ocr4","colab_type":"text"},"cell_type":"markdown","source":"## **Trackables**"},{"metadata":{"id":"Iy-3MVJsW_Z3","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"trackable_type_from = []\ntrackable_value_from = []\ntrackable_name_from = []\nfor row in dataframe['entries_from']:\n  for d in row:\n    for key, value in d.items():\n      if key == 'trackable_name':\n        trackable_name_from.append(value)\n      elif key == 'trackable_type':\n        trackable_type_from.append(value)\n      else:\n        trackable_value_from.append(value)","execution_count":0,"outputs":[]},{"metadata":{"id":"T6WkmrduW_WA","colab_type":"code","outputId":"4bc80a11-f508-43a7-e030-f48fc2e7f4ec","colab":{"base_uri":"https://localhost:8080/","height":281},"trusted":false},"cell_type":"code","source":"sns.countplot(trackable_type_from)\nplt.title(\"Trackable types_from\")\nplt.show()\n","execution_count":0,"outputs":[]},{"metadata":{"id":"0mI-nzq5rm_N","colab_type":"code","outputId":"b1b88c9d-0542-447f-f3bf-3c7282f2e8a0","colab":{"base_uri":"https://localhost:8080/","height":482},"trusted":false},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nstopwords = set(STOPWORDS) \nstring_from = (\" \").join(trackable_name_from)\nwordcloud = WordCloud(width = 2000, height = 2000, \n                background_color ='black', \n                stopwords = stopwords, \n                min_font_size = 10).generate(string_from)  \nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.title('Wordcloud of trackable names_from')\nplt.show()\n","execution_count":0,"outputs":[]},{"metadata":{"id":"QBjFK--1ykZ4","colab_type":"code","outputId":"34bd2731-f50d-4444-ef1b-dad7c2858762","colab":{"base_uri":"https://localhost:8080/","height":499},"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(15,8))\npd.Series(trackable_name_from).value_counts().head(35).plot(kind= 'barh' )\nplt.title('Trackable Names_from')\nplt.show()\n","execution_count":0,"outputs":[]},{"metadata":{"id":"XjzF0K6yRKYB","colab_type":"text"},"cell_type":"markdown","source":"Looks like Anxiety is the leading problem. Let us see which age group is affected by anxiety"},{"metadata":{"id":"LwpLUpfSAthd","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"anxiety_age_from = []\nfor index, row in dataframe['entries_from'].items():\n  #print(index)\n  for d in row:\n    for key, value in d.items():\n      if value == 'Anxiety':\n        age = dataframe['age'][index]\n        anxiety_age_from.append(age)\n","execution_count":0,"outputs":[]},{"metadata":{"id":"ZzodKZKVAtkf","colab_type":"code","outputId":"97223567-3e47-4f24-f73b-2dd5d1e7960b","colab":{"base_uri":"https://localhost:8080/","height":298},"trusted":false},"cell_type":"code","source":"pd.Series(anxiety_age_from).value_counts().head(5).plot(kind = 'bar')\nplt.title(\"Most Leading problem of the disease fibromyalgia is Anxiety observed in the ages of 24 and 32 \")\nplt.xlabel('Age')\nplt.ylabel('Counts')\nplt.show()\n","execution_count":0,"outputs":[]},{"metadata":{"id":"xo8RBsKe-L1y","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"","execution_count":0,"outputs":[]},{"metadata":{"id":"kDsHrP6_8prw","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"","execution_count":0,"outputs":[]},{"metadata":{"id":"XHySmspBx1XV","colab_type":"code","outputId":"d02bdc44-a769-48c1-dd6f-0900b96382e7","colab":{"base_uri":"https://localhost:8080/","height":482},"trusted":false},"cell_type":"code","source":"string_from = (\" \").join(trackable_value_from)\nwordcloud = WordCloud(width = 2000, height = 2000, \n                background_color ='black', \n                stopwords = stopwords, \n                min_font_size = 10).generate(string_from)  \nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.title('Wordcloud of trackable values_from')\nplt.show()\n","execution_count":0,"outputs":[]},{"metadata":{"id":"2p_qbsaeAtdw","colab_type":"code","outputId":"76db9b9c-45c5-4919-e69b-49ba369227d5","colab":{"base_uri":"https://localhost:8080/","height":499},"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(15,8))\npd.Series(trackable_value_from).value_counts().head(30).plot(kind= 'barh')\nplt.title('Trackable Value_from')\nplt.show()\n","execution_count":0,"outputs":[]},{"metadata":{"id":"VJjuCpVwXBK_","colab_type":"code","outputId":"3056e6b4-ea60-479b-a3f8-1e7cf61ec775","colab":{"base_uri":"https://localhost:8080/","height":374},"trusted":false},"cell_type":"code","source":"dataframe.head()","execution_count":0,"outputs":[]},{"metadata":{"id":"bdPwkvWqGa4X","colab_type":"text"},"cell_type":"markdown","source":"# Parsing trackable_types"},{"metadata":{"id":"4bZvABJ4qzNr","colab_type":"code","outputId":"3e6dbb55-aa50-45a3-9be0-6e45b081f62c","colab":{"base_uri":"https://localhost:8080/","height":601},"trusted":false},"cell_type":"code","source":"Symptoms = []\nTreatments= []\nConditions = []\nWeather = []\n\n\nfor index, row in dataframe['entries_from'].items():\n  for d in row:\n    for key, value in d.items():\n      if value == 'Symptom':\n        Symptoms.append(d.get(\"trackable_name\"))\n      elif value == 'Treatment':\n        Treatments.append(d.get(\"trackable_name\"))\n      elif value == 'Condition':\n        Conditions.append(d.get(\"trackable_name\"))\n      elif value == 'Weather':\n        Weather.append(d.get(\"trackable_name\"))\n\nplt.subplot(2,2,1)\npd.Series(Symptoms).value_counts().head().plot(kind = 'barh')\nplt.title(\"Types of Symptoms\")\nplt.show()\nplt.subplot(2,2,2)\npd.Series(Conditions).value_counts().head().plot(kind = 'barh')\nplt.title(\"Types of Conditions\")\nplt.show()\nplt.subplot(2,2,3)\npd.Series(Treatments).value_counts().head().plot(kind = 'barh')\nplt.title(\"Types of Treatments\")\nplt.show()\nplt.subplot(2,2,4)\npd.Series(Weather).value_counts().head().plot(kind = 'barh')\nplt.title(\"Types of Weather\")\nplt.show()\n\n","execution_count":0,"outputs":[]},{"metadata":{"id":"so9cNJX1smZ8","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"#dataframe.drop(['symptoms'], axis = 1, inplace= True)\n#dataframe.drop(['conditions'], axis = 1, inplace= True)\n#dataframe.drop(['treatments'], axis = 1, inplace= True)\n#dataframe.drop(['weather'], axis = 1, inplace= True)\n\ndef symp(col):\n  symptoms = []\n  for d in col:\n    for key, value in d.items():\n      if value == 'Symptom':\n        symptoms.append(d.get(\"trackable_name\"))\n  return ','.join(symptoms)\ndef cond(col):\n  conditions = []\n  for d in col:\n    for key, value in d.items():\n      if value == 'Condition':\n        conditions.append(d.get(\"trackable_name\"))\n  return ','.join(conditions)\ndef treat(col):\n  treatments = []\n  for d in col:\n    for key, value in d.items():\n      if value == 'Treatment':\n        treatments.append(d.get(\"trackable_name\"))\n  return ','.join(treatments)\ndef weat(col):\n  weather = []\n  for d in col:\n    for key, value in d.items():\n      if value == 'Weather':\n        weather.append(d.get(\"trackable_name\"))\n  return ','.join(weather)\n\n\n\ndataframe['symptoms']  = dataframe['entries_from'].apply(symp)\ndataframe['conditions']  = dataframe['entries_from'].apply(cond)\ndataframe['treatments']  = dataframe['entries_from'].apply(treat)\ndataframe['weather']  = dataframe['entries_from'].apply(weat)","execution_count":0,"outputs":[]},{"metadata":{"id":"-OL7B5lScT8z","colab_type":"code","outputId":"a9cab9a0-4359-4c94-e2c0-b15f410f0480","colab":{"base_uri":"https://localhost:8080/","height":606},"trusted":false},"cell_type":"code","source":"dataframe[['symptoms', 'conditions', 'treatments', 'weather']]","execution_count":0,"outputs":[]},{"metadata":{"id":"gUZJmjKGZUKO","colab_type":"code","outputId":"236338eb-3447-4e58-c137-8f04f5d6526d","colab":{"base_uri":"https://localhost:8080/","height":68},"trusted":false},"cell_type":"code","source":"import nltk\nnltk.download('stopwords')","execution_count":0,"outputs":[]},{"metadata":{"id":"OHjGaJhnd_L5","colab_type":"code","outputId":"547feb0e-911a-4a19-c3df-75c046dfa595","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":false},"cell_type":"code","source":"string.punctuation","execution_count":0,"outputs":[]},{"metadata":{"id":"DcyVuKzgXmeK","colab_type":"code","outputId":"7d29d349-800e-44ec-9c2a-7179d251c586","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":false},"cell_type":"code","source":"from nltk.stem import SnowballStemmer\nimport string\nfrom nltk.corpus import stopwords\nstemmer = SnowballStemmer(\"english\")\n\ndef cleanText(para):\n    #print(para)\n    para = para.replace(',', \" \")\n    para = para.translate(str.maketrans(',',' ',string.punctuation))\n    words = [stemmer.stem(word) for word in para.split() if word.lower() not in stopwords.words(\"english\")]\n    \n    return \" \".join(words)\n\ndataframe[\"symptoms\"] = dataframe[\"symptoms\"].apply(cleanText)\ndataframe[\"conditions\"] = dataframe[\"conditions\"].apply(cleanText)\ndataframe[\"treatments\"] = dataframe[\"treatments\"].apply(cleanText)\ndataframe[\"weather\"] = dataframe[\"weather\"].apply(cleanText)\ndataframe.head(n = 10)    ","execution_count":0,"outputs":[]},{"metadata":{"id":"9iBsoiIng5CY","colab_type":"text"},"cell_type":"markdown","source":"Creating a new column called text with all the data in symptoms, treatments, conditions, weather combined"},{"metadata":{"id":"x7JLYOJ9uFUW","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"dataframe['text'] = dataframe['symptoms'] + ' ' + dataframe['conditions'] + ' ' + dataframe['treatments'] + ' ' + dataframe['weather']","execution_count":0,"outputs":[]},{"metadata":{"id":"DzmkaIae4pm6","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"def encode_labels(label):\n    if label == 'IMPROVED' or label == 'female':\n        return 0\n    elif label == 'WORSENED' or label ==  'male':\n        return 1\n    elif label == 'doesnt_say':\n        return 3\n    else:\n        return 2\n","execution_count":0,"outputs":[]},{"metadata":{"id":"rlGqKE7k7h6q","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ndataframe['country'] = encoder.fit_transform(dataframe['country']) ","execution_count":0,"outputs":[]},{"metadata":{"id":"z-96JsTN5hSC","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"dataframe['y'] = example_df.status.apply(encode_labels)\ndataframe['sex'] = example_df.sex.apply(encode_labels)","execution_count":0,"outputs":[]},{"metadata":{"id":"WDIGRxlihSK3","colab_type":"code","outputId":"51cc3fa4-8baf-4a81-ed61-38cbd4f552b2","colab":{"base_uri":"https://localhost:8080/","height":785},"trusted":false},"cell_type":"code","source":"dataframe.head()","execution_count":0,"outputs":[]},{"metadata":{"id":"RA33JiEMYt88","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"","execution_count":0,"outputs":[]},{"metadata":{"id":"3_6PaGh3YvT8","colab_type":"text"},"cell_type":"markdown","source":"# **Modelling with text from combined columns of Symptoms, Conditions, Weather, Treatment**"},{"metadata":{"id":"RbZqp9e36FKm","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(dataframe['text'], dataframe['y'], train_size=0.8, random_state=23123)\n","execution_count":0,"outputs":[]},{"metadata":{"id":"EQVw9PAl6awF","colab_type":"code","outputId":"60e392f5-bb9b-46c4-fbe2-2bcb1cc012bd","colab":{"base_uri":"https://localhost:8080/","height":221},"trusted":false},"cell_type":"code","source":"X_train","execution_count":0,"outputs":[]},{"metadata":{"id":"DKng-fDNZGZy","colab_type":"text"},"cell_type":"markdown","source":"Using Count Vectorizer with Word Embeddings"},{"metadata":{"id":"yxxeQ5iRx-Co","colab_type":"code","outputId":"148e6388-d6fc-4afd-ec47-33d273174357","colab":{"base_uri":"https://localhost:8080/","height":119},"trusted":false},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()\nvectorizer.fit(X_train)\nvectorizer.fit(X_test)","execution_count":0,"outputs":[]},{"metadata":{"id":"uR39JrU_yV1f","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"\nfrom keras.preprocessing.sequence import pad_sequences\nword2idx = {word: idx for idx, word in enumerate(vectorizer.get_feature_names())}\ntokenize = vectorizer.build_tokenizer()\npreprocess = vectorizer.build_preprocessor()\n \ndef to_sequence(tokenizer, preprocessor, index, text):\n    words = tokenizer(preprocessor(text))\n    indexes = [index[word] for word in words if word in index]\n    return indexes\n\nX_train_sequences = [to_sequence(tokenize, preprocess, word2idx, x) for x in X_train]\nmax_sqeunce=60\nlabels_len = len(vectorizer.get_feature_names())\nX_train_sequences = pad_sequences(X_train_sequences, maxlen=max_sqeunce, value=labels_len)\nX_test_sequences = [to_sequence(tokenize, preprocess, word2idx, x) for x in X_test]\nX_test_sequences = pad_sequences(X_test_sequences, maxlen=max_sqeunce, value=labels_len)","execution_count":0,"outputs":[]},{"metadata":{"id":"BR1mKFE8zXf4","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"\nemb_len = 300\nembeddings_index = np.zeros((len(vectorizer.get_feature_names()) + 1, emb_len))\nfor word, idx in word2idx.items():\n    try:\n        embedding = nlp.vocab[word].vector\n        embeddings_index[idx] = embedding\n    except:\n        pass\n","execution_count":0,"outputs":[]},{"metadata":{"id":"3K9AMzOxbKTR","colab_type":"text"},"cell_type":"markdown","source":"Using LSTM"},{"metadata":{"id":"A6PWoQ1jxk0v","colab_type":"code","outputId":"6819bb29-1359-4019-c73a-f490d787fdca","colab":{"base_uri":"https://localhost:8080/","height":272},"trusted":false},"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Activation,Input,concatenate, BatchNormalization,Dense, Dropout,Flatten, LSTM, Embedding\nmodel = Sequential()\nmodel.add(Embedding(len(vectorizer.get_feature_names()) + 1,\n                    EMBEDDINGS_LEN,  # Embedding size\n                    weights=[embeddings_index],\n                    input_length=MAX_SEQ_LENGHT,\n                    trainable=False))\nmodel.add(LSTM(300, dropout=0.2))\nmodel.add(Dense(3, activation='softmax'))\n \nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())","execution_count":0,"outputs":[]},{"metadata":{"id":"DtfxyL8rzyFE","colab_type":"code","outputId":"ba71c287-96b7-4ecb-d556-b84d6927216c","colab":{"base_uri":"https://localhost:8080/","height":408},"trusted":false},"cell_type":"code","source":"model.fit(X_train_sequences, y_train, \n          epochs=10, batch_size=128, verbose=1, \n          validation_split=0.1)\n \nscores = model.evaluate(X_test_sequences, y_test, verbose=1)\nprint(\"Accuracy:\", scores[1])  ","execution_count":0,"outputs":[]},{"metadata":{"id":"68hhOsV8aBoA","colab_type":"text"},"cell_type":"markdown","source":"Accuracy is barely 50% which should be improved.  Including multiple features such as age, sex, country"},{"metadata":{"id":"O2CrI6nB1N1o","colab_type":"code","outputId":"975de7dd-a0c4-4d27-8feb-863bba1cdab2","colab":{"base_uri":"https://localhost:8080/","height":493},"trusted":false},"cell_type":"code","source":"text_data = Input(shape=(max_sqeunce,), name='text')\nmeta_data = Input(shape=(3,), name = 'meta')\nx=(Embedding(len(vectorizer.get_feature_names()) + 1,\n                    300,  \n                    weights=[embeddings_index],\n                    input_length=max_sqeunce,\n                    trainable=False))(text_data)\nx2 = ((LSTM(300, dropout=0.2, recurrent_dropout=0.2)))(x)\nx4 = concatenate([x2, meta_data])\nx5 = Dense(150, activation='relu')(x4)\nx6 = Dropout(0.25)(x5)\nx7 = BatchNormalization()(x6)\nout=(Dense(len(set(y_train)), activation=\"softmax\"))(x7)\nmodel = Model(inputs=[text_data, meta_data ], outputs=out)\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())","execution_count":0,"outputs":[]},{"metadata":{"id":"Ydh9H-ab-yWG","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"df_cat_train = dataframe.iloc[X_train.index][['age', 'sex', 'country']]\ndf_cat_test = dataframe.iloc[X_test.index][[ 'age','sex', 'country']]","execution_count":0,"outputs":[]},{"metadata":{"id":"24397geZ-yQe","colab_type":"code","outputId":"849e64bf-685a-41a1-fa1e-619eeb7714ae","colab":{"base_uri":"https://localhost:8080/","height":102},"trusted":false},"cell_type":"code","source":"df_cat_train['sex'].value_counts()","execution_count":0,"outputs":[]},{"metadata":{"id":"84GQp_lZAOCz","colab_type":"code","outputId":"a556bf0d-e1b6-448a-d998-4303b7d05851","colab":{"base_uri":"https://localhost:8080/","height":476},"trusted":false},"cell_type":"code","source":"model.fit([X_train_sequences, df_cat_train], y_train, \n          epochs=12, batch_size=128, verbose=1, \n          validation_split=0.1)\n \nscores = model.evaluate([X_test_sequences, df_cat_test],y_test, verbose=1)\nprint(\"Accuracy:\", scores[1])  \n","execution_count":0,"outputs":[]},{"metadata":{"id":"yZJWVXkVawmr","colab_type":"text"},"cell_type":"markdown","source":"Accuracy haven't improved. Maybe adding more feature isn't helping  much. Let's try without combining extracted features"},{"metadata":{"id":"Y59zj7jB4paR","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"class ItemSelector(TransformerMixin):\n    \"\"\"This class allows you to select a subset of a dataframe based on a given column name.\n    If as_feature is False, you will need to pass the data to another Transformer to convert it into features; \n    otherwise, scikit-learn will throw dimension related exception.\n    If as_feature is True, the column from that dataframe you just pass in will be use as feature directly. \n    For example, if 'key' is set to 'age' from the dataset, the values from the 'age' column will be used as features\n    without the need for another Transformer.\n    \"\"\"\n    def __init__(self, key, as_feature=False):\n        self.key = key\n        self.as_feature = as_feature\n\n    def fit(self, x, y=None):\n        return self\n\n    def transform(self, dataframe):\n        if self.as_feature:\n            return dataframe[[self.key]]\n        return dataframe[self.key]","execution_count":0,"outputs":[]},{"metadata":{"id":"NLv2UzKFKWyS","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(dataframe, dataframe[\"y\"], test_size = 0.2)","execution_count":0,"outputs":[]},{"metadata":{"id":"hh8NrNTg5toR","colab_type":"code","outputId":"0a3f39ec-e1c8-448e-fdaf-1258acc8923d","colab":{"base_uri":"https://localhost:8080/","height":629},"trusted":false},"cell_type":"code","source":"\npipeline = Pipeline([\n        \n    ('union', FeatureUnion(\n        transformer_list=[\n        \n            ('age', Pipeline([\n                ('selector', ItemSelector('age', as_feature=True))\n            ])),\n            ('sex', Pipeline([\n                ('selector', ItemSelector('sex', as_feature=True))\n            ])),\n            ('country', Pipeline([\n                ('selector', ItemSelector('country', as_feature=True))\n            ])),\n            ('symptoms', Pipeline([\n                ('selector', ItemSelector('symptoms')),\n                ('cnt', CountVectorizer()),\n                \n            ])),\n             ('conditions', Pipeline([\n                ('selector', ItemSelector('conditions')),\n                ('cnt', CountVectorizer()),\n                \n            ])),\n             ('treatments', Pipeline([\n                ('selector', ItemSelector('treatments')),\n                ('cnt', CountVectorizer()),\n               \n            ])),\n             ('weather', Pipeline([\n                ('selector', ItemSelector('weather')),\n                ('cnt', CountVectorizer())\n            ])),\n\n            \n           \n            \n        ],\n\n    )),\n\n    # Use a naive bayes classifier on the combined features\n    #('clf', MultinomialNB()),\n])\n\n\npipeline.fit(X_train, y_train)\n","execution_count":0,"outputs":[]},{"metadata":{"id":"bOmAxkgfySu_","colab_type":"text"},"cell_type":"markdown","source":"# KNN"},{"metadata":{"id":"4FXpDv_awFTR","colab_type":"code","outputId":"18a7d1cf-1639-4991-e694-69095fb4c428","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":false},"cell_type":"code","source":"train = pipeline.transform(X_train)\ntest = pipeline.transform(X_test)\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(train, y_train)\ny_pred = knn.predict(test)\nprint(accuracy_score(y_test, y_pred))","execution_count":0,"outputs":[]},{"metadata":{"id":"5uyg7NTIzDWc","colab_type":"text"},"cell_type":"markdown","source":"# SVM"},{"metadata":{"id":"Czqm7GzmeA7h","colab_type":"code","outputId":"78db621e-d55e-4ac6-f3cc-41f4d1fa3948","colab":{"base_uri":"https://localhost:8080/","height":68},"trusted":false},"cell_type":"code","source":"from sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score\nsvm = LinearSVC( max_iter=10000)\nsvm.fit(train, y_train)\ny_pred = svm.predict(test)\nprint(accuracy_score(y_test, y_pred))\n#scores = cross_val_score(svm,train, y_train, cv=3, scoring=\"accuracy\" )\n#print(np.mean(scores))","execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"gDERxuFs1zIr"},"cell_type":"markdown","source":"# Naive Bayes"},{"metadata":{"id":"adW8xJGn3apk","colab_type":"code","outputId":"52bf5113-5c1a-4683-c6d2-16403a05f87c","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":false},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nNB = MultinomialNB()\nNB.fit(train, y_train)\ny_pred = NB.predict(test)\nprint(accuracy_score(y_test, y_pred))","execution_count":0,"outputs":[]},{"metadata":{"id":"6lxJIWd9HuOa","colab_type":"text"},"cell_type":"markdown","source":"### Additional Questions\n\nPlease answer the following questions:\n\n**1.   If you've explored the data, please describe your observations about the dataset.**\n\n**Answer:**\n\n\n1.   Trackable_name and trackable_type from entries_from and entries_to tables are same. There is only change in trackable_value\n2.   Most of the observations are given by females\n3.   Highly recorded\n                  symptom = Headache, Fatigue\n                  condition = Depression, Anxiety\n                  Treatments = Tramadol\n                  weather = icon, pressure, tem_min,tem,max, precip_Intensity\n4.   Anxiety is the Leading problem for the disease fibromyalgia which is  observed between the age 24 and 32\n\n5. Data consists of people with ages ranging from 14-79 . Average age is 37\n7. Discrepencies in ages with values -1, 0 ,1. Replaced them with mean\n8. Most people with age 58 and 62 reported worsened disease status\n\n\n\n**2.   What approach (i.e. modeling & evaluation) did you use?**\n\nFirstly, features: symptoms, treatments, conditions and weather were extracted from list of dictionaries. Latitude and Longitude data for countries were generated to plot on a interactive Folium map. \n\nBasic exploration of data using pandas, matplotlib, seaborn, nltk.Text Cleaning which consists of stopwords, punctuation removal, stemming. \n\nUsed CountVectorization and Word Embeddings to train combined  textual data on LSTM with 51% validation accuracy. Added more features like age, sex, country. Model couldn't distinguish target properly.\n\nCompared accuracies using Support Vector Machines (SVM), K-Nearest Neighbors (KNN), Multinomial Naive Bayes (NB) without combining ectracted features and with other meta data. Accuracies are as follows:\n\n        SVM : 45%\n        KNN: 39%\n        NB: 41%\n\n\n\n**3.   What features have you tried (please also include the ones that you do not include in your final model)?**\n\n With Symptoms, Conditions, Treatments, Weather as features along with meta data like age, sex, country all the models are trained. \n\nuserid, checkin_to and checkin_from, value_to, value_from, trackable_value,latitude, longitude aren't included.\n\n**4.   What tradeoffs did you consider? Why did you use this approach?**\n\nAs trackable names and values have a lot of individual observations, if used as features will result in a lot of columns which could be more than number of observations (p > n) where traditional ML models may show ambiguious reslts or may result in extremely sparse dataframe. Hence, I used trackable types with trackable names as its row value and ignored trackale_values for now.\n\n**5.   How would you improve your model if you had more time?**\n\nThis project is genuinely very interesting to work with. My first future enchancement would be finding a way to use trackable value as a feature and see if model performence increases or not. Adding attention layer to the existing LSTM is also one in my mind.\n\n"},{"metadata":{"id":"YWCniYYnQhj-","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"","execution_count":0,"outputs":[]}],"metadata":{"colab":{"name":"Aishwarya Vantipuli QPID ML DS Challenge -- Python 3 -- v1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1}